[
  {"body":"Запрос позволяет найти 10(или больше) самых больших таблиц PostgreSQL по занимаемому месту на диске:\nSELECT schemaname AS \u0026#34;table_schema\u0026#34;, relname AS \u0026#34;table_name\u0026#34;, pg_size_pretty(pg_total_relation_size(relid)) AS total_size, pg_size_pretty(pg_relation_size(relid)) AS data_size, pg_size_pretty(pg_total_relation_size(relid) - pg_relation_size(relid)) AS external_size FROM pg_catalog.pg_statio_user_tables ORDER BY pg_total_relation_size(relid) DESC, pg_relation_size(relid) DESC LIMIT 10; ","title":"10 самых больших таблиц в базе","url":"https://weirdvic.github.io/mycelium/10-%D1%81%D0%B0%D0%BC%D1%8B%D1%85-%D0%B1%D0%BE%D0%BB%D1%8C%D1%88%D0%B8%D1%85-%D1%82%D0%B0%D0%B1%D0%BB%D0%B8%D1%86-%D0%B2-%D0%B1%D0%B0%D0%B7%D0%B5/"}, {"body":"Infrastructure-as-Code или IaC это автоматизированный подход к описанию и управлению IT инфраструктурой не через ручное редактирование файлов конфигураций на серверах, а с применением специальных инструментов. Инструменты IaC являются важной частью практик DevOps и концепций CI/CD.\nПод инфраструктурой в данном случае понимается совокупность аппаратных и программных компонентов, составляющих IT среду, таких как серверы, устройства хранения данных, сетевые устройства и т.д.\nОсновная идея IaC в том чтобы перенести практики, применяющиеся в разработке ПО на управление инфраструктурой. Сам код для управления инфраструктурой может быть написан как в декларативном стиле, так и в императивном. При декларативном подходе описывается желаемое состояние системы (в идеале), а необходимые действия для достижения этого состояния производит инструмент управления конфигурацией. Ну а при императивном подходе мы указываем что конкретно нужно сделать.\nТакже между разными инструментами существует различие в методе инициации обновления. Различают push метод это когда изменения конфигурации приходят с некоего управляющего хоста на управляемые и pull метод, когда управляемые хосты по-расписанию или при других условиях сами запрашивают обновление конфигурации у управляющего хоста.\nК наиболее распространённым в практике инструментам IaC относятся:\nTerraform Cloudformation Ansible SaltStack Puppet Инструменты, использующие IaC подход можно разделить на две большие группы:\nИнструменты для развёртывания(provisioning) инфраструктуры, такие как Terraform и Cloudformation Инструменты для конфигурации инфраструктуры как Ansible, Puppet, Chef Provisioning инфраструктуры это процесс создания компонентов инфраструктуры и предоставления доступа конечным пользователям.\nВажной характеристикой IaC инструментов является идемпотентность.\n","title":"Infrastructure as Code","url":"https://weirdvic.github.io/mycelium/infrastructure-as-code/"}, {"body":"Иногда требуется найти медианное значение в таблице. В отличие от среднего, медиана это значение, разделяющее диапазон на две равные части. В случае равномерного распределения, медиана совпадает со средним арифметическим, но в других случаях может и отличаться. Если диапазон содержит чётное количество значений, медианное приходится на среднее между двумя центральными значениями.\nРассмотрим пример поиска медианного значения северной широты (LAT_N) из таблицы метеостанций.\nSET @row_index := -1; SELECT ROUND(AVG(subq.LAT_N),4) FROM ( SELECT @row_index:=@row_index + 1 AS row_index, LAT_N FROM STATION ORDER BY LAT_N ) AS subq WHERE subq.row_index IN (FLOOR(@row_index / 2) , CEIL(@row_index / 2)); Разберём этот запрос подробнее.\nSET @row_index := -1; Эта строка создаёт переменную @row_index со значением -1.\n( SELECT @row_index:=@row_index + 1 AS row_index, LAT_N FROM STATION ORDER BY LAT_N ) AS subq Здесь мы запрашиваем целевую колонку LAT_N из таблицы STATION, отсортированную по возрастанию значения LAT_N и назначаем каждому столбцу порядковый номер, начиная с 0.\nWHERE subq.row_index IN (FLOOR(@row_index / 2) , CEIL(@row_index / 2)); Это условие позволяет выбрать среднюю строку.\n","title":"Поиск медианы в MySQL","url":"https://weirdvic.github.io/mycelium/%D0%BF%D0%BE%D0%B8%D1%81%D0%BA-%D0%BC%D0%B5%D0%B4%D0%B8%D0%B0%D0%BD%D1%8B-%D0%B2-mysql/"}, {"body":"Что такое DevOps? По этому поводу есть много споров и существует много различных определений DevOps, приведу примеры от разных компаний\nAmazon DevOps это сочетание культурной философии, практик и инструментов, увеличивающее способность организации доставлять приложения и сервисы быстрее: изменять и улучшать продукты быстрее чем организации, использующие традиционный подход к разработке ПО и управлению инфраструктурой. Эта скорость позволяет организациям лучше удовлетворять потребности клиентов и быть более эффективными.\nMicrosoft DevOps это союз людей, процессов и продуктов ради обеспечения непрерывной доставки конечным пользователям.\u0026ldquo;Dev\u0026rdquo; и \u0026ldquo;Ops\u0026rdquo; относится к переходу от отдельных команд разработки и эксплуатации к командам, работающим с использованием общих практик и инструментов. Важнейшими DevOps практиками являются agile планированиеб непрерывная интеграция, непрерывная доставка и мониторинг приложений.\nRed Hat DevOps описывает подход к ускорению процессов перехода от идеи(например новой функции в ПО, багфикса или улучшения) к разработке и внедрению и достижению конечного пользователя. Этот подход требует частой коммуникации команд разработки и эксплуатации и отношения к работе с эмпатией к своим коллегам. Кроме того приветствуется масштабируемость решений и простой запуск.\n","title":"DevOps","url":"https://weirdvic.github.io/mycelium/devops/"}, {"body":"Идемпотентность(idempotency) — свойство объекта или операции при повторном применении операции к объекту давать тот же результат, что и при первом.\nВ контексте IT это характеристика инструментов, которые не вносят дополнительные изменения в систему при перезапусках. Например плейбук Ansible, который создал файлы в системе при первом запуске, при повторном и следующих запусках не должен пытаться снова создать эти файлы если они уже существуют в системе.\n","title":"Идемпотентность","url":"https://weirdvic.github.io/mycelium/%D0%B8%D0%B4%D0%B5%D0%BC%D0%BF%D0%BE%D1%82%D0%B5%D0%BD%D1%82%D0%BD%D0%BE%D1%81%D1%82%D1%8C/"}, {"body":"При запуске сервера Clickhouse после аварийной перезагрузки или проблем с файловой системой может появиться большое число ошибок и сервер просто не запустится. В логах Clickhouse ошибки будут примерно такие:\n2023.07.26 19:26:36.621640 [ 2366 ] {} \u0026lt;Error\u0026gt; Application: DB::Exception: Suspiciously many (29) broken parts to remove.: Cannot attach table anyclass.event from metadata file /var/lib/clickhouse/store/430/430da485-c4de-4665-830d-a485c4de4665/event.sql from query ATTACH TABLE … clickhouse from path /var/lib/clickhouse/metadata/clickhouse В таком случае может помочь создание файла /var/lib/clickhouse/flags/force_restore_data и перезапуск сервера:\nsudo -u clickhouse touch /var/lib/clickhouse/flags/force_restore_data sudo systemctl restart clickhouse-server ","title":"Ошибка suspiciously many broken parts to remove","url":"https://weirdvic.github.io/mycelium/%D0%BE%D1%88%D0%B8%D0%B1%D0%BA%D0%B0-suspiciously-many-broken-parts-to-remove/"}, {"body":"Определение модулей Terraform Модуль представляет собой контейнер для нескольких ресурсов, используемых совместно. Модули могут быть использованы для построения абстракций над базовыми \u0026ldquo;строительными блоками\u0026rdquo; для описания архитектуры на более высоком уровне.\nКак определить модуль Terraform? Фактически любые файлы Terraform в одной директории составляют модуль. Нет специального синтаксиса для определения модулей.\nКак тестировать модули Terraform? Есть несколько различных способов, один из них — использование инструмента terratest для проверки инициализации модуля, создания и удаления ресурсов.\n","title":"Модули Terraform","url":"https://weirdvic.github.io/mycelium/%D0%BC%D0%BE%D0%B4%D1%83%D0%BB%D0%B8-terraform/"}, {"body":"Terraform\nНаписание определений в файлах .tf на языке HCL и запуск команды terraform init (только в первый раз для установки необходимых провайдеров). Проверка планируемых изменений с помощью команды terraform plan. Применение изменений командой terraform apply. ","title":"Типичный рабочий процесс с Terraform","url":"https://weirdvic.github.io/mycelium/%D1%82%D0%B8%D0%BF%D0%B8%D1%87%D0%BD%D1%8B%D0%B9-%D1%80%D0%B0%D0%B1%D0%BE%D1%87%D0%B8%D0%B9-%D0%BF%D1%80%D0%BE%D1%86%D0%B5%D1%81%D1%81-%D1%81-terraform/"}, {"body":"Источники данных используются для получения данных от провайдеров или, в общем смысле, от любых внешних ресурсов (например публичных облаков AWS, GCP и др.) Источники данных только предоставляют данные, ничего не создают и не изменяют.\nПример использования источников данных в Terraform data \u0026#34;aws_vpc\u0026#34; \u0026#34;default { default = true } Обращение к данным внутри источника Допустим источник данных определён таким способом:\ndata \u0026#34;aws_vpc\u0026#34; \u0026#34;default { default = true } Тогда для обращения к его аттрибуту ID можно использовать такой способ: data.aws_vpc.default.id\nКомбинирование источников данных Например мы хотим получить подсети в AWS, но находящиеся только в дефолтной VPC:\ndata \u0026#34;aws_subnets\u0026#34; \u0026#34;default\u0026#34; { filter { name = \u0026#34;vpc-id\u0026#34; values = [data.aws_vpc.default.id] } } Мы используем второй источник данных в качестве фильтра.\n","title":"Data sources в Terraform","url":"https://weirdvic.github.io/mycelium/data-sources-%D0%B2-terraform/"}, {"body":"Определение рабочего пространства из официальной документации довольно расплывчатое. Условно рабочим пространством можно назвать постоянные данные и cостояние(state) для определённого бэкенда. Каждое рабочее пространство обладает собственным файлом состояния. Использовать рабочие пространства для разделения между разными окружениями(например development и production) плохая идея потому что рабочие пространства хранятся в одном месте и к ним применяются одинаковые ограничения доступа. Плюс легко ошибиться и выполнить команду в неправильном пространстве.\nКак создать новое рабочее пространство? terraform workspace new \u0026lt;WORKSPACE_NAME\u0026gt;\nКак определить текущее рабочее пространство? terraform workspace show\n","title":"Workspaces в Terraform","url":"https://weirdvic.github.io/mycelium/workspaces-%D0%B2-terraform/"}, {"body":"Как работает обновление ресурсов? По-умолчанию существующий ресурс удаляется, создаётся новый и все ссылки на старый ресурс заменяются ссылками на новый.\nВозможно ли изменить стандартный жизненный цикл? Да, существует несколько вариантов, например create_before_destroy, при котором порядок обновления изменяется: сначала создаётся новый ресурс, обновляются ссылки, а затем старый ресурс удаляется.\nlifecycle { create_before_destroy = true } Причина для использования такого порядка обновления: в определённых случаях ресурс может иметь иммутабельные зависимости, которые нельзя обновить без пересоздания. В таком случае стандартный жизненный цикл не сработает: сначала придётся пересоздать зависимые ресурсы, а только потом основной.\n","title":"Жизненный цикл ресурсов в Terraform","url":"https://weirdvic.github.io/mycelium/%D0%B6%D0%B8%D0%B7%D0%BD%D0%B5%D0%BD%D0%BD%D1%8B%D0%B9-%D1%86%D0%B8%D0%BA%D0%BB-%D1%80%D0%B5%D1%81%D1%83%D1%80%D1%81%D0%BE%D0%B2-%D0%B2-terraform/"}, {"body":"Даже в случае если сайт хостится за прокси типа Cloudflare, полезно ограничить прямой доступ по IP адресу сервера. В Nginx версии 1.19.4 и новее можно использовать такой конфиг:\nserver { listen 80 default_server; listen [::]:80 default_server; listen 443 default_server; listen [::]:443 default_server; ssl_reject_handshake on; server_name _; return 444; } В более старых версиях для достижения такого же результата придётся сначала сгенерировать самоподписной SSL сертификат:\nsudo openssl req -x509 -nodes -days 3650 -newkey rsa:2048 -keyout default.key -out default.crt -subj \u0026#39;/CN=\u0026#39; После этого можно использовать такой конфиг дефолтного сервера:\nserver { listen 80 default_server; listen [::]:80 default_server; listen 443 default_server; listen [::]:443 default_server; ssl_certificate /etc/nginx/ssl/default.crt; ssl_certificate_key /etc/nginx/ssl/default.key; server_name _; return 444; } ","title":"Запрет доступа по IP адресу","url":"https://weirdvic.github.io/mycelium/%D0%B7%D0%B0%D0%BF%D1%80%D0%B5%D1%82-%D0%B4%D0%BE%D1%81%D1%82%D1%83%D0%BF%D0%B0-%D0%BF%D0%BE-ip-%D0%B0%D0%B4%D1%80%D0%B5%D1%81%D1%83/"}, {"body":"GRANT SELECT ON ALL TABLES IN SCHEMA project_1 TO analytic; ","title":"Изменить разрешения на уровне схемы Изменить разрешения на уровне схемы","url":"https://weirdvic.github.io/mycelium/%D0%B8%D0%B7%D0%BC%D0%B5%D0%BD%D0%B8%D1%82%D1%8C-%D1%80%D0%B0%D0%B7%D1%80%D0%B5%D1%88%D0%B5%D0%BD%D0%B8%D1%8F-%D0%BD%D0%B0-%D1%83%D1%80%D0%BE%D0%B2%D0%BD%D0%B5-%D1%81%D1%85%D0%B5%D0%BC%D1%8B-%D0%B8%D0%B7%D0%BC%D0%B5%D0%BD%D0%B8%D1%82%D1%8C-%D1%80%D0%B0%D0%B7%D1%80%D0%B5%D1%88%D0%B5%D0%BD%D0%B8%D1%8F-%D0%BD%D0%B0-%D1%83%D1%80%D0%BE%D0%B2%D0%BD%D0%B5-%D1%81%D1%85%D0%B5%D0%BC%D1%8B/"}, {"body":"Что такое поставщики (provisioners) Допустим мы создали виртуальную машину и нам необходимо передать ей какие-либо данные или запустить какую-либо команду, как это можно сделать средствами Terraform? Ответ: с использованием provisioners. Поставщики можно описать как плагин для Terraform, позволяющий выполнять некоторые задачи по конфигурации сервисов. Типичные задачи, для которых используются поставщики:\nЗапустить софт для управления конфигурациями, такой как Ansible. Скопировать файлы Выполнить скрипт на удалённой машине Почему к provisioners рекомендуется прибегать только в самом крайнем случае? Поскольку поставщик может выполнять большой диапазон действий, практически невозможно отследить изменения в системе, произошедшие после срабатывания поставщика, так что в случае если можно обойтись средствами провайдера, следует так и поступать.\nЧто такое \u0026ldquo;tainted resource\u0026rdquo; Ресурс, который был успешно создан Terraform, но удалось выкатить.\nДля чего нужен terraform taint? Команда terraform taint resource.id позволяет вручную отметить ресурс как сломаный, так что при следующем запуске terraform apply ресурс будет удалён и создан снова.\n","title":"Использование provisioners в Terraform","url":"https://weirdvic.github.io/mycelium/%D0%B8%D1%81%D0%BF%D0%BE%D0%BB%D1%8C%D0%B7%D0%BE%D0%B2%D0%B0%D0%BD%D0%B8%D0%B5-provisioners-%D0%B2-terraform/"}, {"body":"SELECT \u0026#34;table\u0026#34;, formatReadableSize(sum(bytes)) AS \u0026#34;size\u0026#34; FROM system.parts WHERE active GROUP BY \u0026#34;table\u0026#34; ORDER BY \u0026#34;size\u0026#34; DESC ; ","title":"Какие таблицы Clickhouse занимают место на диске","url":"https://weirdvic.github.io/mycelium/%D0%BA%D0%B0%D0%BA%D0%B8%D0%B5-%D1%82%D0%B0%D0%B1%D0%BB%D0%B8%D1%86%D1%8B-clickhouse-%D0%B7%D0%B0%D0%BD%D0%B8%D0%BC%D0%B0%D1%8E%D1%82-%D0%BC%D0%B5%D1%81%D1%82%D0%BE-%D0%BD%D0%B0-%D0%B4%D0%B8%D1%81%D0%BA%D0%B5/"}, {"body":" Декларативность. Terraform использует декларативный подход для описания конечного состояния ресурсов. Отсутствие агентов. В отличие от других технологий Terraform не использует клиент-серверную модель, а полагается на различные API для выполнения манипуляций с ресурсами. Сильная поддержка сообщества для модулей и провайдеров и наличие большого количества готовых инструментов. ","title":"Особенности Terraform","url":"https://weirdvic.github.io/mycelium/%D0%BE%D1%81%D0%BE%D0%B1%D0%B5%D0%BD%D0%BD%D0%BE%D1%81%D1%82%D0%B8-terraform/"}, {"body":"В файле /etc/clickhouse-server/users.d/disable-query-logging.xml:\n\u0026lt;yandex\u0026gt; \u0026lt;profiles\u0026gt; \u0026lt;default\u0026gt; \u0026lt;log_queries\u0026gt;0\u0026lt;/log_queries\u0026gt; \u0026lt;log_query_threads\u0026gt;0\u0026lt;/log_query_threads\u0026gt; \u0026lt;/default\u0026gt; \u0026lt;/profiles\u0026gt; \u0026lt;/yandex\u0026gt; В новых версиях Clickhouse вместо \u0026lt;yandex\u0026gt; использовать \u0026lt;clickhouse\u0026gt;.\n","title":"Отключение логирования запросов Clickhouse","url":"https://weirdvic.github.io/mycelium/%D0%BE%D1%82%D0%BA%D0%BB%D1%8E%D1%87%D0%B5%D0%BD%D0%B8%D0%B5-%D0%BB%D0%BE%D0%B3%D0%B8%D1%80%D0%BE%D0%B2%D0%B0%D0%BD%D0%B8%D1%8F-%D0%B7%D0%B0%D0%BF%D1%80%D0%BE%D1%81%D0%BE%D0%B2-clickhouse/"}, {"body":"Для чего используются переменные (input variables) в Terraform? Для того же, для чего и в программировании — для обращения по имени к какому-либо значению.\nТипы переменных, поддерживаемые в Terraform? string number bool list(\u0026lt;TYPE\u0026gt;) set(\u0026lt;TYPE\u0026gt;) map(\u0026lt;TYPE\u0026gt;) object({\u0026lt;ATTR_NAME\u0026gt; = \u0026lt;TYPE\u0026gt;, \u0026hellip; }) tuple([\u0026lt;TYPE\u0026gt;, \u0026hellip;]) Какой тип переменной используется по-умолчанию? any\nСпособы передать значения для переменных? С использованием опции -var в командной строке. С использованием файла переменных и опции -var-file. Через переменные окружения, которые начинаются с TF_VAR_\u0026lt;VAR_NAME\u0026gt; Если не значение не было передано, оно будет запрошено в процессе выполнения команды.\nКак сослаться на переменную? С использованием синтакса var.\u0026lt;VAR_NAME\u0026gt;\nКакой смысл отмечать переменные как \u0026ldquo;sensitive\u0026rdquo;? Значение таких переменных не отображается в логах выполнения команд terraform apply и terraform plan, но всё равно попадает в файл состояния. Если результат выражения зависит от значения такой переменной, он тоже становится \u0026ldquo;чувствительным\u0026rdquo;.\nЧто такое выходные переменные (output variables)? Выходные переменные позволяют выводить определённые значения в процессе исполнения команд Terraform. Наверное самый распространённый пример использования таких переменных это вывод IP адреса создаваемого инстанса сразу после его создания.\nПример определения переменной с указанием типа и дефолтными параметрами variable \u0026#34;app_id\u0026#34; { type = string description = \u0026#34;The id of application\u0026#34; default = \u0026#34;some_value\u0026#34; } Примечание: обычно переменные определяются в отдельном файле, например vars.tf\nКак определить переменную-объект с несколькими разными аттрибутами? variable \u0026#34;car_model\u0026#34; { description = \u0026#34;Car model object\u0026#34; type = object({ model = string color = string year = number }) } Пример обращения к переменной В файле vars.tf\nvariable \u0026#34;memory\u0026#34; { type = string default \u0026#34;8192\u0026#34; } variable \u0026#34;cpu\u0026#34; { type = string default = \u0026#34;4\u0026#34; } В файле main.tf\nresource \u0026#34;libvirt_domain\u0026#34; \u0026#34;vm1\u0026#34; { name = \u0026#34;vm1\u0026#34; memory = var.memory cpu = var.cpu } Что такое локали (locals)? Локали это аналог констант в программировании: их значение задаётся один раз и не может быть изменено пользователем.\nПример определения локали locals { x = 2 y = \u0026#34;o\u0026#34; z = 2.2 } Пример использования локали Аналогично использованию переменных, но с ключевым словом local вместо var, например local.x\n","title":"Переменные в Terraform","url":"https://weirdvic.github.io/mycelium/%D0%BF%D0%B5%D1%80%D0%B5%D0%BC%D0%B5%D0%BD%D0%BD%D1%8B%D0%B5-%D0%B2-terraform/"}, {"body":"Terraform использует систему плагинов, называемых провайдерами (providers) для взаимодействия с облачными платформами или другими сервисами посредством API.\nУже существует более 1000 провайдеров для управления ресурсами на:\nAmazon Web Services (AWS) Google Cloud Platform (GCP) Oracle Cloud Azure Kubernetes GitHub Splunk DataDog и огромным количеством других.\nРепозиторий провайдеров находится в Terraform Registry\n","title":"Провайдеры Terraform","url":"https://weirdvic.github.io/mycelium/%D0%BF%D1%80%D0%BE%D0%B2%D0%B0%D0%B9%D0%B4%D0%B5%D1%80%D1%8B-terraform/"}, {"body":"Под состоянием или state в Terraform понимается состояние инфраструктуры и конфигурации, о котором \u0026ldquo;знает\u0026rdquo; Terraform. При этом оно вполне может отличаться от фактического состояния ресурсов. В самом простом варианте состояние хранится в файле terraform.tfstate и представляет собой JSON файл. Лучшие практики в работе с tfstate:\nНе редактировать файл состояния вручную. Файл не предназначен для ручного редактирования. Хранить файл в защищённом месте, поскольку в нём содержаться секретные данные в виде простого текста. Делать регулярные бэкапы файлов состояния. В случае работы команды файл состояния надо хранить в удалённом хранилище, желательно с поддержкой версионирования для возможности отката к старым версиям. Какая команда создаёт файл состояния? terraform apply\nКак просмотреть текущее состояние? terraform show\nКак просмотреть ресурсы, созданные через Terraform? terraform state list\nКак переименовать существующий ресурс? terraform state mv\nПереключение на удалённый бэкенд По умолчанию для работы с состоянием используется бэкенд local, но можно и нужно использовать удалённые бэкенды на свой выбор. Переключение бэкенда на примере перехода на S3:\nНаписать tf код для создания бакета в S3, хорошей идеей будет добавить параметр prevent_destroy в жизненный цикл. Включить версионирование бакета. Включить шифрование. Заблокировать публичный доступ. Решить как будет реализована блокировка. Применить код чтобы бакет был создан. Переключиться в коде на использование удалённого бэкенда: terraform { backend \u0026#34;s3\u0026#34; { bucket ... } } Запустить terraform init чтобы переключиться на удалённый бэкенд. Что меняется в выполнении terraform apply при использовании удалённого бэкенда? Выполнение terraform apply начинается с блокировки состояния чтобы предотвратить изменения в конфигурацию ресурсов.\nКак переключиться обратно с удалённого бэкенда на локальный? Удалить код, определяющий удалённый бэкенд и снова запустить terraform init Удалить ресурсы, представляющие сам бэкенд(например, бакет в случае S3) Возможно ли использовать переменные в конфигурации бэкенда? Нет, нельзя. Придётся вручную пойти в консоль облачного провайдера и скопировать значения оттуда. Есть костыль в виде хранения части конфигурации бэкенда локально и загрузке её при выполнении: terraform init -backend-config=some_backend_partial_conf.hcl\nКак можно получить данные из удалённого бэкенда? С использованием источников данных. В частности, можно использовать такой синтакс: data.terraform_remote_state.\u0026lt;NAME\u0026gt;.outputs.\u0026lt;ATTRIBUTE\u0026gt;\n","title":"Состояние в Terrafrom","url":"https://weirdvic.github.io/mycelium/%D1%81%D0%BE%D1%81%D1%82%D0%BE%D1%8F%D0%BD%D0%B8%D0%B5-%D0%B2-terrafrom/"}, {"body":"Как определить переменную в виде списка чисел? variable \u0026#34;list_of_nums\u0026#34; { type = list(number) description = \u0026#34;An example of list of numbers\u0026#34; default = [2, 0, 1, 7] } Как создать ресурсы в количестве, равном длине списка? resource \u0026#34;some_resource\u0026#34; \u0026#34;some_name\u0026#34; { count = length(var.some_list) } Как получить аттрибут \u0026ldquo;name\u0026rdquo; второго элемента списка \u0026ldquo;users\u0026rdquo;? users[1].name Как получить аттрибут \u0026ldquo;name\u0026rdquo; всех элементов списка \u0026ldquo;users\u0026rdquo;? users[*].name Для чего используются циклы в Terraform? Чаще всего для создания нескольких ресурсов, различающихся незначительно: например только именем.\nПример простого цикла в Terraform resource \u0026#34;aws_instance\u0026#34; \u0026#34;server\u0026#34; { count = 15 } Эта конфигурация создаст 15 экземпляров инстансов AWS. Если мы хотим задать имена здесь же, фрагмент кода будет выглядеть так:\nresource \u0026#34;aws_instance\u0026#34; \u0026#34;server\u0026#34; { count = 15 tags = { Name = \u0026#34;instance-${count.index}\u0026#34; } } Как использовать значения из списка в цикле? Допустим, у нас есть такой список имён пользователей:\nvariable \u0026#34;users\u0026#34; { type = list(string) default = [\u0026#34;mario\u0026#34;, \u0026#34;luigi\u0026#34;, \u0026#34;peach\u0026#34;] } Чтобы создать пользователей(или другой ресурс) с именами из списка, можно использовать такой код:\nresource \u0026#34;aws_iam_user\u0026#34; \u0026#34;user\u0026#34; { count = length(var.users) name = var.users[count.index] } Ограничения при использовании count сount нельзя использовать во вложенных блоках. использование count в работе со списками имеет свои особенности. Например, при удалении элементов из списка, остальные элементы меняют индекс, что может привести к непредвиденным последствиям. Есть способы избежать такого поведения, но в целом при использовании count нужно быть осторожным. Что такое цикл for_each и чем он отличается от count? for_each может использоваться только с типами коллеций, как мапы(maps) и наборы(sets), в отличие от count, применяемого со списками. for_each может использоваться во вложенных блоках. Пример использования цикла for_each resource “google_compute_instance” “instances” { for_each = var.names_map name = each.value } Как for_each используется во вложенных блоках? resouce \u0026#34;some_instance\u0026#34; \u0026#34;instance\u0026#34; { dynamic \u0026#34;tag\u0026#34; { for_each = var.tags content { key = tag.key value = tag.value } } } ","title":"Структуры данных Terraform","url":"https://weirdvic.github.io/mycelium/%D1%81%D1%82%D1%80%D1%83%D0%BA%D1%82%D1%83%D1%80%D1%8B-%D0%B4%D0%B0%D0%BD%D0%BD%D1%8B%D1%85-terraform/"}, {"body":"Иногда требуется автоматически перенаправлять запросы с www-доменов на домен без www. В Nginx это можно сделать следующим образом:\nserver { server_name ~^(www\\.)(?\u0026lt;domain\u0026gt;.+)$; return 301 $scheme://$domain$request_uri; } Важно отметить что этот способ будет хорошо работать только для HTTP запросов. В случае с HTTPS придётся добавлять версию домена с www в сертификат сайта.\n","title":"Удаление www из URL","url":"https://weirdvic.github.io/mycelium/%D1%83%D0%B4%D0%B0%D0%BB%D0%B5%D0%BD%D0%B8%D0%B5-www-%D0%B8%D0%B7-url/"}, {"body":"В файле /etc/clickhouse-server/config.d/set-log-level.xml:\n\u0026lt;yandex\u0026gt; \u0026lt;logger\u0026gt; \u0026lt;level\u0026gt;warning\u0026lt;/level\u0026gt; \u0026lt;console\u0026gt;true\u0026lt;/console\u0026gt; \u0026lt;/logger\u0026gt; \u0026lt;query_thread_log remove=\u0026#34;remove\u0026#34;/\u0026gt; \u0026lt;query_log remove=\u0026#34;remove\u0026#34;/\u0026gt; \u0026lt;text_log remove=\u0026#34;remove\u0026#34;/\u0026gt; \u0026lt;trace_log remove=\u0026#34;remove\u0026#34;/\u0026gt; \u0026lt;metric_log remove=\u0026#34;remove\u0026#34;/\u0026gt; \u0026lt;asynchronous_metric_log remove=\u0026#34;remove\u0026#34;/\u0026gt; \u0026lt;/yandex\u0026gt; В новых версиях Clickhouse вместо \u0026lt;yandex\u0026gt; использовать \u0026lt;clickhouse\u0026gt;. Также можно отключить дополнительные логи:\n\u0026lt;session_log remove=\u0026#34;remove\u0026#34;/\u0026gt; \u0026lt;part_log remove=\u0026#34;remove\u0026#34;/\u0026gt; ","title":"Уменьшение уровня логирования Clickhouse","url":"https://weirdvic.github.io/mycelium/%D1%83%D0%BC%D0%B5%D0%BD%D1%8C%D1%88%D0%B5%D0%BD%D0%B8%D0%B5-%D1%83%D1%80%D0%BE%D0%B2%D0%BD%D1%8F-%D0%BB%D0%BE%D0%B3%D0%B8%D1%80%D0%BE%D0%B2%D0%B0%D0%BD%D0%B8%D1%8F-clickhouse/"}, {"body":"Как использовать условные выражения в Terraform? some_condition ? \u0026#34;value_if_true\u0026#34; : \u0026#34;value_if_false\u0026#34; Возможно ли сочетать условные выражения и циклы? dynamic \u0026#34;tag\u0026#34; { for_each = { for key, value in var.tags: key =\u0026gt; value if key != \u0026#34;\u0026#34; } } ","title":"Условные выражения в Terraform","url":"https://weirdvic.github.io/mycelium/%D1%83%D1%81%D0%BB%D0%BE%D0%B2%D0%BD%D1%8B%D0%B5-%D0%B2%D1%8B%D1%80%D0%B0%D0%B6%D0%B5%D0%BD%D0%B8%D1%8F-%D0%B2-terraform/"}, {"body":"Мета-аргументы влияют на жизненный цикл ресурса и поддерживаются вне зависимости от типа ресурса. Например:\ncount — количество ресурсов, которые нужно создать или изменить из единого определения. lifecycle — как поступать в случае необходимости создания или удаления ресурса. depends_on — создание зависимости между ресурсами. ","title":"Что такое мета-аргументы Terraform?","url":"https://weirdvic.github.io/mycelium/%D1%87%D1%82%D0%BE-%D1%82%D0%B0%D0%BA%D0%BE%D0%B5-%D0%BC%D0%B5%D1%82%D0%B0-%D0%B0%D1%80%D0%B3%D1%83%D0%BC%D0%B5%D0%BD%D1%82%D1%8B-terraform/"}, {"body":"Terraform это инструмент с открытым исходным кодом, разрабатываемый HashiCorp. Terraform предназначен для реализации концепции Infrastructure as Code (IaC) в части управления IT инфраструктурой. Terraform обычно использует HashiCorp Configuration Language (HCL) для декларативного описания желаемого состояния конфигурации. Сам Terraform написан на Go и предоставляет утилиту командной строки terraform.\nДля управления различными инфраструктурными ресурсами Terraform использует так называемые \u0026ldquo;провайдеры\u0026rdquo; (providers) Если провести аналогию с софтом для работы с базами данных, то провайдеры Terraform это как драйверы для различных СУБД.\nДругой важной концепцией Terraform являются \u0026ldquo;модули\u0026rdquo; (modules) это сгруппированные логически наборы ресурсов.\nОсобенности Terraform Типичный рабочий процесс с Terraform Жизненный цикл ресурсов в Terraform Состояние в Terrafrom Переменные в Terraform Структуры данных Terraform Условные выражения в Terraform Data sources в Terraform Провайдеры Terraform Workspaces в Terraform Использование provisioners в Terraform Модули Terraform Что такое мета-аргументы Terraform? ","title":"Terraform","url":"https://weirdvic.github.io/mycelium/terraform/"}, {"body":"Kubernetes или K8s это система с открытым исходным кодом для автоматизации развёртывания, масштабирования и управления контейнеризированными приложениями.\n","title":"Kubernetes","url":"https://weirdvic.github.io/mycelium/kubernetes/"}, {"body":" Предыстория Я играю в NetHack уже очень-очень давно. Моё первое непродолжительное знакомство с этой игрой состоялось приблизительно в 2006 году, но на тот момент моего знания английского не хватало на то чтобы полноценно начать играть. Постоянного доступа к интернету для общения с другими игроками у меня в то время не было, сама игра очень сложная без подсказок, так что довольно скоро я оставил попытки и не прошёл даже Гномьи Шахты. Снова вернулся к этой игре я лишь спустя пять лет, уже будучи студентом. Фактически NetHack является той игрой, которая прошла со мной через годы, в которую я играл и играю в разных версиях, на разных устройствах и которая всё ещё имеет огромный простор для реиграбельности и много тайн.\nОдной из таких загадок для меня являлось изображение всадника на красном драконе, появляющееся при запуске графической версии NetHack на Windows, да и на других платформах думаю тоже. И хоть практически с самого начала я играю в режиме без тайлсетов в текстовой псевдографике, этот всадник на дракончике чем-то запал в мою память ещё со школьных лет, когда я впервые запускал NetHack 3.4.3 на компьютере с Windows XP и безуспешно пытался исследовать жестокий мир игры.\nИстория И вот, уже в 2023 году я наконец-то решил разобраться с историей происхождения этой картинки. Начал, как говорится, с начала — с поисков в исходном коде игры, который уже довольно давно доступен на GitHub. В исходниках графической версии довольно быстро нашёлся файл с самим изображением всадника из заголовка этой статьи.\nСейчас я понимаю, что если бы копнул чуть глубже в исходниках, смог бы найти имя автора изображения и уже по имени автора найти исходник. Но об этом чуть позднее. Чтобы установить происхождение драконьего всадника, я создал пост с вопросом в сабреддите r/nethack, где довольно быстро получил ответ — оригинальное изображение участвовало в The Internet Raytracing Competition в 1997 году.\n\u0026ldquo;Dragon Rider\u0026rdquo; (1997) by Warwick Allison: Уже интереснее! Вместе с изображением доступен текстовый файл с указанием авторства и заметкой от том, как было создано конкурсное изображение.\nСначала немного об авторе: это некий Warwick Allison, судя по всему, он был участником DevTeam и поддерживал Qt версию NetHack в нулевых и поэтому добавил свою картинку с драконом. Кроме того он приложил руку и к другим opensource играм, например к Freeciv. Похоже этот канал на YouTube принадлежит ему же, но я не пытался с ним связаться.\nНо что действительно интересно — вместе с готовыми рендерами и текстовыми файлами на сайте IRTC до сих пор доступны архивы с исходниками и в этот момент я задался целью сделать \u0026ldquo;HD ремастер\u0026rdquo; драконьего всадника.\nТехнологии древних После прочтения текстового файла от автора оригинального изображения, я узнал новое для себя слово POV-Ray и открыл для себя древние технологии трёхмерной графики в эпоху до современных редакторов.\nЕсли пытаться объяснить простым языком, то POV-Ray это специальная программа, которая принимает на вход текстовые файлы, содержащие описание трёхмерной сцены(геометрия объектов, расположение камеры, источники освещения, различные эффекты) на специальном языке, а на выходе генерирует растровый графический файл. Из плюсов такого подхода: низкие требования к системе, для работы достаточно текстового редактора, а сам рендер можно запускать на другой машине. Описание сцены по-сути представляет собой программу, получается такой CGI as a code подход, что интересно само по себе. Из очевидных минусов — невозможность смотреть изменения в реальном времени, но с учётом скорости рендера на современных компьютерах и возможности во время разработки использовать низкие настройки качества, это не такая уж и проблема.\nПроект продолжает развиваться, несмотря на свой возраст, кроме уже упомянутого IRTC на официальном сайте есть галерея избранных работ. POV-Ray также используется для создания иллюстраций к различным научным статьям, а кроме того для создания анимаций. Сложилось впечатление, что сейчас это такой не мейнстримный способ создания трёхмерной графики, который может быть даже удобнее условного Blender, например для визуализации научных данных.\nМоя же затея состояла в том чтобы запустить рендеринг исходного изображения с драконьим всадником, используя современную версию POV-Ray и в высоком разрешении. Оригинал был сделан для версии POV-Ray 3.0, я же адаптировал код для актуальной 3.7. Изменений пришлось сделать немного: с определённой версии точки с запятой в конце строк стали обязательными, так что пришлось их добавить и отдельно пришлось разобраться как переписать на современную версию свечение вокруг навершия посоха всадника.\nВот та же картинка, но в разрешении 1900*1080: Кроме того, поскольку мы работаем с исходным кодом, можно проворачивать интересные штуки, например изменить цвета(здесь изображение растянуто вдоль горизонтали потому что на тот момент я ещё не разобрался как указать правильный aspect ratio): Или взглянуть на сцену с другого положения камеры(в коде было закомментировано несколько позиций для камеры): Ну и наконец, отдельные элементы сцены могут включаться и выключаться условными блоками, так что можно отключить всё кроме дракона и всадника и получить улучшенную версию картинки из начала статьи: Итоги Мне нравится такого рода \u0026ldquo;цифровая археология\u0026rdquo;. Вдвойне приятно найти пример технологии, которая жизнеспособна и даже обратно совместима на временном промежутке в 25 лет. Кроме удовлетворения любопытства узнал немного больше об истории и технологиях трёхмерной графики, сделал себе несколько крутых обоин на рабочий стол в ретро стиле и в целом интересно провёл время. Мне кажется что POV-Ray это возможность заниматься 3D как хобби если ты больше программист чем художник.\n","title":"Красный дракон","url":"https://weirdvic.github.io/posts/%D0%BA%D1%80%D0%B0%D1%81%D0%BD%D1%8B%D0%B9-%D0%B4%D1%80%D0%B0%D0%BA%D0%BE%D0%BD/"}, {"body":"Заметки по настройке и обслуживанию СУБД PostgreSQL\nИзменить разрешения на уровне схемы 10 самых больших таблиц в базе ","title":"PostgreSQL","url":"https://weirdvic.github.io/mycelium/postgresql/"}, {"body":"Заметки по настройке и обслуживанию Clickhouse.\nКакие таблицы занимают место на диске Отключение логирования запросов Уменьшение уровня логирования Ошибка suspiciously many broken parts to remove ","title":"Clickhouse","url":"https://weirdvic.github.io/mycelium/clickhouse/"}, {"body":"Один из простых в использовании дистрибутивов Kubernetes.\n","title":"Minikube","url":"https://weirdvic.github.io/mycelium/minikube/"}, {"body":"Введение В этой статье я бы хотел зафиксировать процесс запуска учебного кластера Kubernetes в виде Minikube на сервере под управлением Oracle Linux.\nПодразумевается что сам сервер с доступом по ssh у нас уже есть. Я использую бесплатный инстанс в Oracle Cloud, но в принципе можно использовать любое другое облако или даже любой другой хостинг, вплоть до подкроватного. Для запуска Minikube необходимо минимум 2 ядра процессора и 2 Гб оперативной памяти. Если мы используем free-tier облака от Oracle, то следует использовать машины на Ampere A1. Бесплатных лимитов хватает либо на то чтобы создать 2 машины с двумя ядрами, либо одну с четырьмя.\nЯ использую свою виртуальную машину для изучения Oracle Linux и Podman. Также нам понадобятся установленные на хосте cURL и Nginx. Для генерации пароля нам понадобится утилита htpasswd, в Oracle Linux она входит в пакет с названием httpd-tools. Я буду делать доступ с привязкой домена, для наших целей подойдёт любой домен, вплоть до бесплатных от Freenom. Для большей безопасности и других бонусов я использую прокси от Cloudflare. Обо всём этом подробнее дальше.\nУстанавливаем Minikube Сама по себе установка Minikube довольно простая и описана в документации:\ncurl -LO https://storage.googleapis.com/minikube/releases/latest/minikube-linux-arm64 sudo install minikube-linux-arm64 /usr/local/bin/minikube После этого необходимо создать кластер. Мы используем Podman, это явно нужно указать при создании:\nminikube start --driver=podman После окончания создания кластера, им уже можно пользоваться на удалённой машине, для проверки работоспособности предлагается выполнить команду:\nminikube kubectl -- get pods -A Если всё хорошо, можем двигаться дальше.\nПланируем удалённый доступ Кластер доступен на самом сервере, а мы хотим работать с ним с нашей локальной машины, как поступить в данном случае? По-умолчанию API-сервер Minikube принимает только локальные соединения, а значит нам понадобится настроить Nginx в качестве реверс-прокси, который будет принимать авторизованные запросы на внешний IP нашего сервера и проксировать их на внутренний адрес API Kubernetes.\nИными словами, я хочу достигнуть следующей схемы:\nFigure 1: Схема доступа к Minikube на сервере.\nМы будем отправлять команды при помощи локального kubectl, запросы к API будут уходить на специальный домен или поддомен за Cloudflare, оттуда проксироваться на виртуальную машину с запущенным Minikube. На самой машине хостовый Nginx будет принимать подключения, проверять базовую авторизацию и проксировать доверенные подключения на локальный адрес Minikube.\nНастройка Nginx на сервере Начнём с простого — сгенерируем пароль для защиты нашего подключения, в этой команде minikube — имя пользователя для HTTP авторизации:\nsudo htpasswd -c /etc/nginx/.htpasswd minikube Для примера можем использовать пароль b3VyU3VwZXJTZWNyZXRQYXNzd29yZAo=.\nРазумеется, пароль надо где-нибудь сохранить, он нам ещё понадобится.\nДля того чтобы наш Nginx мог проксировать запросы к Kubernetes API, ему нужны SSL сертификаты и здесь у меня возникла путаница. Поскольку Podman не требует запуска от root-пользователя, Minikube через Podman можно запускать от обычного пользователя. Следовательно, конфиг Minikube будет храниться в домашней директории обычного пользователя(в моих примерах стандартное имя пользователя opc) и файлы из него не будут доступны другим пользователям(например nginx). Самым простым решением будет скопировать файлы ключа и сертификата в директорию Nginx.\nsudo mkdir -p /etc/nginx/certs sudo cp /home/opc/.minikube/profiles/minikube/client.key /etc/nginx/certs/minikube-client.key sudo cp /home/opc/.minikube/profiles/minikube/client.key /etc/nginx/certs/minikube-client.key После этого можем создать конфиг реверс-прокси Nginx. У меня используется SSL сертификаты от Cloudflare, приведу пример той части конфига, которая нас интересует:\n# В http блоке добавляем такую штуку, это способ создать \u0026#34;глобальную переменную\u0026#34; # в конфиге Nginx и в дальнейшем использовать её в разных других блоках. # Быстро узнать адрес API Minikube можно командой minikube ip map $host $MINIKUBE_IP { default \u0026#34;192.168.49.2\u0026#34;; } # Ниже идёт серверный блок для приёма входящих подключений с авторизацией # В примере используется субдомен k.examplehomelab.tk # Сам субдомен предварительно нужно создать в Cloudflare, а также скачать # сертификат и ключ для главного домена. Настройка SSL для Cloudflare это # не очень сложная, хоть и обширная тема, материалов по которой много. # https://developers.cloudflare.com/ssl/get-started/ server { listen 443 ssl http2; # Используем имя субдомена server_name k.examplehomelab.tk; # Используем сертификат основного домена, благо Cloudflare даёт # wildcard сертификат типа *.examplehomelab.tk ssl_certificate \u0026#34;/etc/nginx/ssl/examplehomelab.tk.pem\u0026#34;; ssl_certificate_key \u0026#34;/etc/nginx/ssl/examplehomelab.tk.key\u0026#34;; ssl_session_cache shared:SSL:1m; ssl_session_timeout 10m; ssl_ciphers PROFILE=SYSTEM; ssl_prefer_server_ciphers on; auth_basic \u0026#34;Administrator’s Area\u0026#34;; # Путь к нашему файлу для проверки авторизации auth_basic_user_file /etc/nginx/.htpasswd; # Собственно настройка проксирования запросов к API location / { proxy_http_version 1.1; proxy_pass https://$MINIKUBE_IP:8443; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection \u0026#34;upgrade\u0026#34;; # А здесь сертификат для общения с API Minikube по HTTPS proxy_ssl_certificate /etc/nginx/certs/minikube-client.crt; proxy_ssl_certificate_key /etc/nginx/certs/minikube-client.key; } } Конечно, конфиг не идеален, но для моего сценария использования вполне подходит. Выполняем стандартные манипуляции чтобы обновить конфиг:\nsudo nginx -t sudo service nginx reload На этом этапе уже можно попробовать открыть наш адрес в браузере, если всё настроено корректно, браузер запросит авторизацию, а после ввода логина(minikube) и пароля(b3VyU3VwZXJTZWNyZXRQYXNzd29yZAo=) мы увидим список доступных путей Kubernetes API. Можем двигаться дальше, к настройке локального kubectl.\nНастройка kubectl Настал момент настроить подключение к кластеру с нашей локальной машины. По-умолчанию на сервере конфигурация Minikube хранится в файле ~/.kube/config. Скопируем этот файл к себе на машину по тому же пути, он будет выглядеть примерно так:\napiVersion: v1 clusters: - cluster: certificate-authority: /home/opc/.minikube/ca.crt extensions: - extension: last-update: Tue, 30 May 2023 13:39:51 GMT provider: minikube.sigs.k8s.io version: v1.30.1 name: cluster_info server: https://192.168.49.2:8443 name: minikube contexts: - context: cluster: minikube extensions: - extension: last-update: Tue, 30 May 2023 13:39:51 GMT provider: minikube.sigs.k8s.io version: v1.30.1 name: context_info namespace: default user: minikube name: minikube current-context: minikube kind: Config preferences: {} users: - name: minikube user: client-certificate: /home/opc/.minikube/profiles/minikube/client.crt client-key: /home/opc/.minikube/profiles/minikube/client.key Нужно поправить пару мест.\nЗаменяем server: https://192.168.49.2:8443 на наш внешний адрес сервера. В конце файла закомментировать или удалить строчки client-certificate и client-key, а вместо них добавить username со значением minikube и password со значением нашего пароля для HTTP авторизации. Сохраняем файл и проверяем работоспособность:\nkubectl get all -A Для дополнительной безопасности ещё можно использовать правила Cloudflare чтобы ограничить доступ к API по стране или IP адресу если он у вас статический.\nНа этом всё, в дальнейшем можно работать с кластером так же как и с запущенным локально Minikube.\n","title":"Установка Minikube в Oracle Linux","url":"https://weirdvic.github.io/posts/%D1%83%D1%81%D1%82%D0%B0%D0%BD%D0%BE%D0%B2%D0%BA%D0%B0-minikube-%D0%B2-oracle-linux/"}, {"body":"Ansible — наиболее популярная в настоящий момент система управления конфигурациями, написана на языке Python.\n","title":"Ansible","url":"https://weirdvic.github.io/mycelium/ansible/"}, {"body":"Google Cloud Platform (GCP) — облачная платформа от Google, наряду с AWS и Azure входит в тройку крупнейших.\n","title":"Google Cloud Platform","url":"https://weirdvic.github.io/mycelium/google-cloud-platform/"}, {"body":"Hugo — популярный генератор статических вебсайтов, написанный на Go.\n","title":"Hugo","url":"https://weirdvic.github.io/mycelium/hugo/"}, {"body":"Тип прокси сервера, который транслирует запросы клиентов из внешней сети на серверы, расположенные во внутренней сети.\nРеверс-прокси используется во многих случаях:\nОбратный прокси-сервер может скрывать существование опрашиваемых им серверов и их характеристики. Применение программного файрвола в обратном прокси-сервере может защитить от наиболее распространенных веб-атак, таких как DoS или DDoS. Без обратного прокси-сервера удаление вредоносного ПО может оказаться непростой задачей. Основной веб-сайт может не поддерживать подключение по SSL, однако это можно реализовать с помощью обратного прокси-сервера, который может быть оборудован аппаратным SSL-ускорителем. Выполнение функций балансировщика нагрузки между несколькими серверами, подменяя URL таким образом, чтобы использовался наиболее уместный сервер. Уменьшение нагрузки на основные сервера благодаря кэшированию статического и динамического контента. Эта возможность известна как акселерация веб-сайтов. Сервер может отсортировать свой кэш по частоте запросов к контенту, что значительно уменьшит нагрузку на основные серверы. Сжатие содержимого для уменьшения времени его загрузки. В методе, называемом «spoon feeding», страницы, генерируемые динамически, могут быть отданы обратному прокси-серверу для освобождения ресурсов сервера-генератора от затрат на их отдачу медлительным клиентам. Может выполнять тестирование, например, A/B-тестирование, изменяя код страниц. Полученные данные можно использовать для последующей оптимизации. ","title":"Реверс-прокси","url":"https://weirdvic.github.io/mycelium/%D1%80%D0%B5%D0%B2%D0%B5%D1%80%D1%81-%D0%BF%D1%80%D0%BE%D0%BA%D1%81%D0%B8/"}, {"body":"Go — компилируемый многопоточный язык программирования, изначально разработанный Google.\nНа Go написано множество полезных инструментов, особенно в области DevOps:\nDocker Kubernetes Terraform Hugo ","title":"Язык программирования Go","url":"https://weirdvic.github.io/mycelium/%D1%8F%D0%B7%D1%8B%D0%BA-%D0%BF%D1%80%D0%BE%D0%B3%D1%80%D0%B0%D0%BC%D0%BC%D0%B8%D1%80%D0%BE%D0%B2%D0%B0%D0%BD%D0%B8%D1%8F-go/"}, {"body":"Cloudflare — сервис, предоставляющий услуги защиты от DDoS, CDN и множество других сервисов.\n","title":"Cloudflare","url":"https://weirdvic.github.io/mycelium/cloudflare/"}, {"body":"Docker — платформа для управления контейнеризованными приложениями.\n","title":"Docker","url":"https://weirdvic.github.io/mycelium/docker/"}, {"body":"Nginx — популярный HTTP-сервер, реверс-прокси, почтовый прокси, а также TCP/UDP прокси общего назначения.\nПолезные советы по настройке:\nУдаление www из URL Запрет доступа по IP адресу ","title":"Nginx","url":"https://weirdvic.github.io/mycelium/nginx/"}, {"body":"Дистрибутив Linux на базе RHEL, разрабатываемый Oracle.\n","title":"Oracle Linux","url":"https://weirdvic.github.io/mycelium/oracle-linux/"}, {"body":"Podman — утилита для управления контейнерами, альтернатива Docker.\nПосле установки на Oracle Linux для скачивания контейнеров с DockerHub необходимо залогиниться:\npodman login docker.io По-умолчанию в rootless режиме Podman не умеет цепляться к портам ниже 1024, документация по этому поводу предлагает несколько вариантов решения этой проблемы кроме запуска Podman от рута:\nВ sysctl установить значение net.ipv4.ip_unprivileged_port_start равное минимальному порту, который требуется открывать от непривиллегированного пользователя. То есть если нужно прослушивать 80 порт, это значение должно быть не больше 80. Использовать прокси, правило для фаерволла или специализированные инструменты для редиректа трафика с разрешённого порта на системный. ","title":"Podman","url":"https://weirdvic.github.io/mycelium/podman/"}, {"body":"Uptime Kuma — selfhosted сервис для мониторинга статуса сервисов.\nЗапуск в podman:\npodman volume create uptime-kuma podman run --detach --restart=always -p 127.0.0.1:3001:3001 -v uptime-kuma:/app/data --name uptime-kuma docker.io/louislam/uptime-kuma:1 [2023-05-15 Пн] Запустил внутри podman на сервере xorn в Oracle Cloud. Для доступа снаружи привязал домен trapperkobold.tk в Cloudflare. Для Uptime Kuma зарегистрировал отдельный субдомен uk.trapperkobold.tk и настроил реверс-прокси Nginx. По-умолчанию Nginx в Oracle Linux из-за настроек SELinux не умеет цепляться к локальным портам, это можно исправить командой:\nsetsebool httpd_can_network_connect on -P ","title":"Uptime Kuma","url":"https://weirdvic.github.io/mycelium/uptime-kuma/"}, {"body":"Недавно я начал использовать org-roam для управления своими заметками при помощи Emacs. Самим Emacs я пользуюсь уже довольно давно, но перечень задач, выполняемый в этой прекрасной \u0026ldquo;операционной системе\u0026rdquo; периодически изменяется. Прелесть Emacs, как многие уже отмечали, в том что это не цель, но путь. Можно начать использовать его как простой текстовый редактор, а затем постепенно добавлять или убирать функции, подстраивая систему под свой рабочий процесс. Часто это означает что ты перестаёшь пользоваться отдельной программой потому что её функции доступны и в Emacs. Так было у меня с отдельным эмулятором терминала когда я открыл для себя vterm. В другой раз я попытался настроить Emacs для работы с базами данных, но довольно быстро понял что использовать отдельный специализировнный инструмент в виде DBeaver лично мне намного удобнее. В этот же раз речь пойдёт о задаче ведения заметок и о том как это можно делать при помощи Emacs.\nДля ведения различных рабочих и не очень заметок в последние годы я использовал org-mode в самом базовом варианте. У меня был один единственный файл ~/work.org, в который каждый рабочий день за каждым рабочим днём я добавлял записи о том чем занимался вчера и чем планирую заняться сегодня. Выглядело это упрощённо вот так:\n* [2020-02-19] Что сделал: - Задача 1… Подробности по задаче - Задача 2… - Задача 3… Что сделать: - [X] Задача 1… - [ ] Задача 2… Подробное описание задачи 2… - [X] Задача 3… Такой способ организации и ведения заметок может показаться примитивным, но на период когда я им пользовался, это был идеальный баланс между удобством ведения такого журнала и пользой от его ведения. Иногда всё что требуется сохранить это простой список дел, которые нужно отмечать в течение дня, какой-то кусок кода или ссылку и не более того. Конечно, я рассматривал и альтернативы вроде Google Keep, но в конечном итоге оказалось что ведение заметок в Emacs лично мне удобнее, а необходимости часто делиться содержимым заметок с кем-либо у меня нет.\nТак или иначе, в определённый момент я стал использовать org-mode и для не связанных с работой заметок, например для хобби-проектов. Стали появляться новые org файлы, разбросанные по разным местам и никак не систематизированные. Кроме того, во время прохождения различных курсов и туториалов полезно делать хоть небольшие конспекты, которые также нужно где-то сохранять. Был соблазн собрать вообще все заметки в один мастер-файл notes.org и я знаю что некоторые пользователи Emacs придерживаются такого подхода. Но мне захотелось более структурированного решения для создания персональной базы знаний с возможностями поиска, отсутствием привязки к сторонним онлайн сервисам и удобным интерфейсом. Разворачивание собственной вики показалось громоздким, онлайн сервисы типа Notion мне не нравятся именно из-за онлайновости и проблем с доступностью функций и самих данных: сегодня функция n есть в бесплатном тарифе, завтра она может оказаться уже только в платном, а послезавтра сделают премиум фичей экспорт данных из сервиса.\nВ общем, под мои пожелания в итоге подошли два продукта: Obsidian и уже упомянутый org-roam. Обе системы предназначены для ведения базы связанных между собой заметок, хранят данные в локально в простом текстовом формате и обладают возможностями расширения за счёт плагинов в случае Obsidian и за счёт мощи Emacs Lisp в случае org-roam. При этом порог вхождения однозначно ниже у Obsidian, с которого я и решил начать. Программа кроссплатформенная, легко устанавливается (в случае с Linux можно даже просто скачать и запустить AppImage файл), читать документацию чтобы просто начать добавлять заметки не требуется, интерфейс можно сказать интуитивный. В целом впечатления от использования очень приятные, наверное лучший вариант в своей категории если вы не пользователь Emacs. Я же пользуюсь Emacs и через несколько дней работы с Obsidian понял что держать отдельную программу только для заметок мне не нравится. И так хватает двух браузеров (Firefox и Chromium) и двух мессенджеров (Telegram и рабочий Google Chat) чтобы ещё держать рядом с работающим Emacs параллельно запущенный Obsidian. Кстати говоря, перенос мессенджеров внутрь Emacs это тоже вполне реально, но об этом в другой раз. Примерно через неделю использования Obsidian я решил что всё же стоит потратить время и усилия на конфиг Emacs и перейти на org-roam.\nЧто представляет из себя org-roam? Сайт проекта говорит об \u0026ldquo;a plain-text personal knowledge management system\u0026rdquo; и по-сути так оно и есть. Org-roam это система, построенная поверх емаксового org-mode и позволяющая структурированно хранить заметки в org файлах со связями между заметками для организации базы знаний. Хороший ресурс для начала знакомства с системой это её мануал, в котором описаны базовые функции, вводится терминология и приводятся примеры конфигурации Emacs для начала работы. После прочтения мануала начинается увлекательный процесс допиливания системы под свои потребности aka \u0026ldquo;копипаст и переписывание кусков кода из чужих конфигов\u0026rdquo;.\nОдна из сильных сторон Emacs и одновременно его слабостей (см. The Lisp Curse) — очень редко есть единственный популярный и поддерживаемый способ делать что-либо. С одной стороны существование альтернатив это хорошо, но с другой это усложняет выбор обучение в случае если ты совсем новичок и для тебя все альтернативы отличаются лишь названиями. Причём эта особенность присутствует практически на всех уровнях взаимодействия с Emacs. Сейчас наиболее используемой версией Emacs является GNU Emacs, но были времена когда существовала альтернатива в виде XEmacs. Сам GNU Emacs нынче можно установить как в относительно ванильной версии, так и в виде преднастроенных \u0026ldquo;дистрибутивов\u0026rdquo; вроде Doom Emacs или Spacemacs. Внутри самого Emacs существует сильно больше одного способа управления сторонними пакетами, лично я пользуюсь use-package. Даже для org-roam как системы ведения заметок существует своя альтернатива — Denote и в ходе поиска информации по настройкам org-roam я встречал упоминания о том что иногда люди переходят с одной системы на другую.\nВ ходе настройки своего Emacs я использовал эти статьи:\nMy org-roam workflows for taking notes and writing articles My Org Roam Notes Workflow И даже несмотря на всё это, меня удивило то как реализован поиск по заметкам в org-roam. А организован он почти что никак — в уже упомянутом стартовом мануале есть небольшой пункт про настройку полнотекстового поиска посредством Deft, но на этом и всё. Deft, как уже можно догадаться, тоже не единственный в своём роде, как минимум есть Xeft. Но вообще поиск по Реддиту и Гитхабу показал что пользователи org-roam готовят поиск по заметкам кому как нравится. Для себя я остановился на consult-org-roam, его функция поиска использует ripgrep или обычный grep для поиска по файлам в org-roam.\nДругой функцией, доступной из коробки в Obsidian является просмотр графа связей между отдельными заметками. Для org-roam существует пакет org-roam-ui, который просто устанавливается в Emacs и позволяет по-всякому визуализировать связи между нодами:\nFigure 1: Связи между нодами org-roam на момент написания статьи\nПосле настройки визуализации и создания первых заметок на различные темы надо было решить что сделать со старым файлом ~/work.org. Вариантов было немного:\nДобавить файл в org-roam \u0026ldquo;как есть\u0026rdquo;. В таком случае на графе это была бы единственная точка. Разделить файл на отдельные заметки по дням, и в дальнейшем создавать новые заметки с использованием org-roam daily. Я выбрал второй вариант, поэтому на графе много ни с чем не связанных нод. При желании их легко можно исключить из визуализации:\nFigure 2: Граф связей в org-roam без daily заметок\nЕдиный файл с заметками я разделил на отдельные файлы с помощью небольшого скрипта на Python:\n#!/usr/bin/env python3 import re,hashlib,time # Задаём регулярное выражение, по которому будем определять, является ли # текущая строка заголовком первого уровня в оригинальном org файле. # В моём случае все заголовки первого уровня в файле имеют такой формат: # * [2020-02-19 Ср] # Собрать нужную регулярку можно на https://regex101.com/ headingRX = re.compile(r\u0026#39;^\\*\\s\\[(\\d{4}-\\d{2}-\\d{2})\\s[а-яА-я]{2,3}\\]$\u0026#39;) # Создаём хэш-объект, который будем использовать для генерации униальных ID # каждого создаваемого org-roam файла. hasher = hashlib.md5() def createOrgRoamFile(): \u0026#39;\u0026#39;\u0026#39;Создает новый org-roam файл с шаблоном текста.\u0026#39;\u0026#39;\u0026#39; # Получаем md5-хэш от значения текущей даты и текущего времени hasher.update(f\u0026#39;{currentDate}-{time.time()}\u0026#39;.encode(\u0026#39;utf-8\u0026#39;)) # Хэш будет использоваться в качестве ID ноды в org-roam nodeID = hasher.hexdigest() # Создаем шаблон, который будет записан в начало org-roam файла. # В минимальном варианте он будет выглядеть так: # :PROPERTIES: # :ID: \u0026lt;nodeID\u0026gt; # :END: # #+title: \u0026lt;currentDate\u0026gt; # #+date: [\u0026lt;currentDate\u0026gt;] # # Ниже будет собственно содержимое заметки. orgRoamTemplate = f\u0026#39;:PROPERTIES:\\n:ID: {nodeID}\\n:END:\\n#+title: {currentDate}\\n#+date: [{currentDate}]\\n\\n\u0026#39; # Записываем шаблон в начало org-roam файла, используя currentDate в качестве названия файла. with open(f\u0026#39;{currentDate}.org\u0026#39;, \u0026#39;w\u0026#39;) as output_file: output_file.write(orgRoamTemplate) def splitOrgFile(inputFileName:str=\u0026#39;notes.org\u0026#39;) -\u0026gt; None: \u0026#39;\u0026#39;\u0026#39;Разделяет входной org-mode файл на отдельные ноды org-roam. В качестве имени файла по-умолчанию используется notes.org.\u0026#39;\u0026#39;\u0026#39; # В переменной currentDate будет храниться дата из текущего заголовка. # Дата используется при генерации ID создаваемой org-roam ноды, в шаблоне # заметки, а также в качестве имени создаваемого файла. global currentDate currentDate = \u0026#39;\u0026#39; with open(inputFileName, \u0026#39;r\u0026#39;) as inputFile: # Буффер для временного хранения строк файла перед записью в org-roam buffer = [] # Читаем файл построчно for line in inputFile: # Если это первый найденный заголовок if not currentDate and headingRX.match(line): # Извлекаем дату из заголовка и открываем новый файл currentDate = headingRX.search(line).group(1) createOrgRoamFile() # Если мы уже нашли заголовок и создали файл и текущая строка # не является заголовком, добавляем строку во временный буфер. elif currentDate and not headingRX.match(line): buffer.append(line) # Если же мы уже нашли заголовок и создали файл и текущая строка # является заголовком, значит текущая строка — это новый заголовок. # Записываем буфер в файл, очищаем его и создаём новый файл. elif currentDate and headingRX.match(line): # Дописываем содержимое буфера в текущий файл with open(f\u0026#39;{currentDate}.org\u0026#39;, \u0026#39;a\u0026#39;) as output_file: output_file.writelines(buffer) # Очищаем буфер, извлекаем дату из нового заголовка # и создаём новый файл. buffer = [] currentDate = headingRX.search(line).group(1) createOrgRoamFile() if __name__ == \u0026#39;__main__\u0026#39;: splitOrgFile() И наконец, одной из самых интересных функций, которые можно реализовать в Emacs является генерация вебсайта из коллекции заметок. Как всегда есть несколько способов собирать сайт из org файлов, я решил использовать связку из org-roam и генератора статических сайтов Hugo. Собственно, удобство ведения блога из Emacs и привело к созданию этого сайта.\nПосты в моём случае это просто заметки org-roam, которые содержат в блоке :PROPERTIES: параметр :KIND: post. После того как пост написан, достаточно нажать C-c n p и org файл будет экспортирован в Markdown, который потом используется Hugo для генерации HTML страницы сайта.\nПредполагаю что настройка Emacs ещё неоднократно будет изменяться, поэтому смысла приводить здесь фрагменты кода нет. Актуальную версию можно посмотреть в моём репозитории.\n","title":"Миграция в org-roam","url":"https://weirdvic.github.io/posts/%D0%BC%D0%B8%D0%B3%D1%80%D0%B0%D1%86%D0%B8%D1%8F-%D0%B2-org-roam/"}
]
